{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#機械学習モデルをリストに格納\n",
    "models = []\n",
    "models.append((\"KNC1\",KNeighborsClassifier()))\n",
    "models.append((\"KNC2\",KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append((\"DTC\",DecisionTreeClassifier()))\n",
    "models.append((\"SVC\",SVC()))\n",
    "models.append((\"BNB\",BernoulliNB()))\n",
    "models.append((\"ETC\",ExtraTreesClassifier()))\n",
    "models.append((\"GNB\",GaussianNB()))\n",
    "models.append((\"GBC\",GradientBoostingClassifier()))\n",
    "models.append((\"KNC\",KNeighborsClassifier()))\n",
    "models.append((\"LDA\",LinearDiscriminantAnalysis()))\n",
    "models.append((\"LSCV\",LinearSVC()))\n",
    "models.append((\"PAC\",PassiveAggressiveClassifier()))\n",
    "models.append((\"QDA\",QuadraticDiscriminantAnalysis()))\n",
    "models.append((\"RFC\",RandomForestClassifier()))\n",
    "models.append((\"SGDC\",SGDClassifier()))\n",
    "models.append((\"LR\",LogisticRegression()))\n",
    "models.append((\"MLPC\",MLPClassifier()))\n",
    "models.append((\"CCCV\",CalibratedClassifierCV()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#複数のclassifier の適用\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    skfold = StratifiedKFold(n_splits=10, shuffle=True,random_state=10)\n",
    "    result = cross_val_score(model,X_fe_train,y_fe_train, cv = skfold,scoring = \"f1\")\n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "\n",
    "#適用したclassifierのスコア表示\n",
    "for i in range(len(names)):\n",
    "    print(names[i],results[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier GS\n",
    "\n",
    "param_grid={\"n_neighbors\":range(1,9,2),\n",
    "            \"weights\" : [\"uniform\", \"distance\"],\n",
    "            \"leaf_size\":range(10,90,10),\n",
    "        \n",
    "           }\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# (モデルのインスタンス, 試したいパラメータの値, 分割方法)\n",
    "gs_mlpc = GridSearchCV(KNeighborsClassifier(n_jobs=-1,algorithm=\"auto\"), param_grid, cv=kf,scoring=\"f1\")\n",
    "gs_mlpc.fit(X_fe_train, y_fe_train)\n",
    "print(gs_mlpc.best_params_)\n",
    "print(gs_mlpc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostingClassifier GS\n",
    "\n",
    "param_grid={\"min_samples_split\":[2,25,50],\n",
    "            \"min_samples_leaf\":[1,5,10],\n",
    "            \"max_depth\":[5,10,15,20],\n",
    "            \n",
    "           }\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# (モデルのインスタンス, 試したいパラメータの値, 分割方法)\n",
    "gs_mlpc = GridSearchCV(GradientBoostingClassifier(learning_rate=0.1,random_state=1,loss=\"deviance\",subsample=0.8), param_grid, cv=kf,scoring=\"f1\")\n",
    "gs_mlpc.fit(X_fe_train, y_fe_train)\n",
    "print(gs_mlpc.best_params_)\n",
    "print(gs_mlpc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pred=model.predict(X_fe_test)\n",
    "print('-'*50)\n",
    "print(accuracy_score(pred, y_fe_test.ravel()))\n",
    "print(precision_score(pred, y_fe_test.ravel()))\n",
    "print(recall_score(pred, y_fe_test.ravel()))\n",
    "print(f1_score(pred, y_fe_test.ravel()))\n",
    "\n",
    "pred =model.predict(X_fe_train)\n",
    "\n",
    "print('-'*50)\n",
    "y_stat = y_fe_train\n",
    "\n",
    "print(accuracy_score(pred, y_stat.ravel()))\n",
    "print(precision_score(pred, y_stat.ravel()))\n",
    "print(recall_score(pred, y_stat.ravel()))\n",
    "print(f1_score(pred, y_stat.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomForestReg\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor(n_estimators=80,max_features=\"auto\")\n",
    "rf.fit(X_fe_train,y_fe_train)\n",
    "print(\"importance\",np.argsort(-rf.feature_importances_))\n",
    "print(\"eigenvalue\",rf.feature_importances_)\n",
    "plt.plot(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see corr\n",
    "import seaborn as sns\n",
    "Xdf=pd.DataFrame(X_fe_scl)\n",
    "plt.figure(figsize=(24, 18))\n",
    "sns.heatmap(Xdf.corr(),annot=True,fmt=\"1.1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open pickle\n",
    "import pickle\n",
    "\n",
    "f = open('svc_leftnoisy.pickle','rb')\n",
    "model=pickle.load(f)\n",
    "\n",
    "# save as pickle\n",
    "\n",
    "with open(fname, 'wb') as f:\n",
    "  pickle.dump(target, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras model \n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': range(1500,30100,3000),\n",
    "              'gamma': np.arange(0.001,0.101,0.02)}\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# (モデルのインスタンス, 試したいパラメータの値, 分割方法)\n",
    "gs_svc = GridSearchCV(SVC(), param_grid, cv=kf,scoring=\"f1\")\n",
    "gs_svc.fit(X_fe_train, y_fe_train)\n",
    "print(gs_svc.best_params_)\n",
    "print(gs_svc.best_score_)\n",
    "\n",
    "df = pd.DataFrame(gs_svc.cv_results_)\n",
    "df.loc[:,[\"params\",\"mean_test_score\",\"rank_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#現在の最大表示列数の出力\n",
    "pd.get_option(\"display.max_columns\")\n",
    "\n",
    "#最大表示列数の指定（ここでは50列を指定）\n",
    "pd.set_option('display.max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "print(random.uniform(100, 200))\n",
    "# 175.26585048238275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# 平均 50, 標準偏差 10 の正規乱数を1,000件生成\n",
    "x = np.random.normal(50, 10, 1000)\n",
    " \n",
    "# ヒストグラムを出力\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show counter\n",
    "for i in range(a):\n",
    "    sys.stdout.write(\"\\r%d / %d\" % (i,a-1) ) \n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from pydub.effects import normalize\n",
    "Y=AudioSegment.from_file(\"./0321/PoC0319/wav/143207.wav\", format=\"wav\")\n",
    "play(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "#load wav file in the directory\n",
    "def importwav(dirname):\n",
    "    path = os.path.join(dirname,\"*wav\")\n",
    "    label_list = sorted(glob.glob(path))\n",
    "    for i,filename in enumerate(label_list):\n",
    "        temp = librosa.load(os.path.join(dirname,filename),sr=44100)\n",
    "        if i==0:            \n",
    "            datalist = temp\n",
    "        else:\n",
    "            datalist = np.concatenate((datalist,temp),axis=0)\n",
    "            \n",
    "    return label_list,datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_speech_features as mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show elapsed time\n",
    "import time\n",
    "\n",
    "%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiprocessing\n",
    "\n",
    "\n",
    "import threading\n",
    "import numpy as np\n",
    "import multiprocessing as multi\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process(n):\n",
    "    A = []\n",
    "    for i in range(n):\n",
    "        A.append(i)\n",
    "    return sum(A)\n",
    "\n",
    "\n",
    "\n",
    "# ----- set params -----\n",
    "# n_job = multi.cpu_count() -1\n",
    "n_job = 3\n",
    "# ----------------------\n",
    "\n",
    "p = Pool(multi.cpu_count() - 1)\n",
    "result = p.map(process, list(range(100)))\n",
    "p.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
